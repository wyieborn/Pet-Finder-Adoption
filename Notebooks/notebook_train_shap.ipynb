{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from Configuration import config\n",
    "from Services import service\n",
    "from Tuning import model_tuning\n",
    "from Preprocess import processdata\n",
    "\n",
    "\n",
    "import mlflow \n",
    "from mlflow import MlflowClient\n",
    "\n",
    "model_path = config.MODEL_PATH\n",
    "model_name = config.MODEL_NAME\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_rf(X, y, grid_cv, model_save_path):\n",
    "    client = MlflowClient(tracking_uri=\"http://127.0.0.1:5001\")\n",
    "    mlflow.start_run(run_name=\"Random_forest_model_v2_Robert\")\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    # Create a base model\n",
    "    rf = RandomForestClassifier()\n",
    "    model_pipeline =  processdata.data_encoding_pipeline() \n",
    "    try:\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "            print('{} directory created'.format(model_path))\n",
    "        \n",
    "        \n",
    "            \n",
    "        if not model_save_path:\n",
    "            model_save_path='{}/{}'.format(model_path, model_name) # add versioning here\n",
    "                \n",
    "        if grid_cv:\n",
    "            if not os.path.exists(model_save_path):\n",
    "                print(\"Grid Search CV Started. Calculating Best Params-------------------------\\n\")\n",
    "                model_ = Pipeline(steps=[('preprocessor', model_pipeline),\n",
    "                        ('classifier', rf)]) \n",
    "                grid = model_tuning.compute_gscv(Xtrain, ytrain, model_, config.GRIDCV_PARAM)\n",
    "                print(\"Grid Search CV completed-----------------------------------\\n\")\n",
    "                print(\"Best Params are :\",grid.best_estimator_)\n",
    "                # Saving the best model to a file\n",
    "                model = grid.best_estimator_\n",
    "                joblib.dump(model, model_save_path)\n",
    "                print(f\"Best Random Forest model saved to {model_save_path}\")\n",
    "                \n",
    "\n",
    "            else:\n",
    "                print('Found a model\\n')\n",
    "                # Loading the pre-trained model from file\n",
    "                model = joblib.load(model_save_path)\n",
    "                print(f\"Random Forest model loaded from {model_save_path}\")\n",
    "                \n",
    "        else : \n",
    "            \n",
    "            # model = Pipeline(steps=[('preprocessor', model_pipeline),\n",
    "            #           ('classifier', \n",
    "            #            RandomForestClassifier(n_jobs=-1, n_estimators=200)\n",
    "            #              )]) \n",
    "            model = Pipeline(steps=[('preprocessor', model_pipeline),\n",
    "                      ('classifier', \n",
    "                    #    RandomForestClassifier(**config.RF_BEST_PARAMS)\n",
    "                        RandomForestClassifier(n_jobs=-1, n_estimators=200)\n",
    "                         )]) \n",
    "            model.fit(Xtrain, ytrain)\n",
    "            joblib.dump(model, model_save_path)\n",
    "            print(f\"Random Forest model saved to {model_save_path}\")\n",
    "            \n",
    "        eval_rf(model, Xtrain, Xtest, ytrain, ytest)\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Exception :',e)\n",
    "   \n",
    "\n",
    "\n",
    "def eval_rf(model, Xtrain, Xtest, ytrain, ytest):\n",
    "    y_model = model.predict(Xtest)\n",
    "    y_model_train = model.predict(Xtrain)\n",
    "\n",
    "    # Accuracy\n",
    "    print(\"Random Forest Train Accuracy: \", accuracy_score(ytrain, y_model_train))\n",
    "    print(\"Random Forest Test Accuracy: \", accuracy_score(ytest, y_model))\n",
    "    \n",
    "    # Log test metrics\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy_score(ytest, y_model))\n",
    "    mlflow.log_metric(\"train_accuracy\", accuracy_score(ytrain, y_model_train))\n",
    "\n",
    "    if config.DEBUG:\n",
    "        service.plot_confusion_matrix(y_model, ytest)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Processing Started...............\n",
      "Saved image features found .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/04 18:55:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Initiated...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/04 18:55:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\data\\pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/12/04 18:56:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\models\\signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved to Models/random_forest_model_v2.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/04 18:56:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n",
      "2023/12/04 18:56:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\data\\pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/12/04 18:56:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n",
      "2023/12/04 18:56:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Escritorio\\Personal_brand\\Data_Science\\Portfolio\\python_envs\\projects_env\\Lib\\site-packages\\mlflow\\data\\pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy:  0.965883886310109\n",
      "Random Forest Test Accuracy:  0.9065029496501578\n"
     ]
    }
   ],
   "source": [
    "from Preprocess import processdata\n",
    "from Services import service\n",
    "from Configuration import config\n",
    "from Src import train\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "train_dir = config.TRAIN_DIR\n",
    "image_dir = config.TRAIN_IMAGE_DIR\n",
    "\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5001\")\n",
    "mlflow.start_run(run_name=\"Random_forest_model_v2_Robert\")\n",
    "#mlflow.autolog(log_metrics=False) \n",
    "\n",
    "def train_model():\n",
    "    df   = service.load_data(train_dir)\n",
    "    print('Feature Processing Started...............')\n",
    "\n",
    "    final_dataframe = processdata.process_train(df)\n",
    "    print('Training Initiated...............')\n",
    "\n",
    "    model = train.train_rf(final_dataframe)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return model\n",
    "    \n",
    "def predict_data(df, img):\n",
    "    final_dataframe = processdata.process(df, image_dir) \n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    model=train_model()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap values and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X=pd.read_csv(r\"data\\train\\train.csv\")\n",
    "y=X[\"AdoptionSpeed\"]\n",
    "X=X.drop(\"AdoptionSpeed\", axis=1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[:-1].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation=model[\"preprocessor\"].transform(Xtest[:50])\n",
    "\n",
    "data_transformed=pd.DataFrame(model[\"preprocessor\"].transform(Xtest).toarray(), \n",
    "                columns=model[:-1].get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer=shap.KernelExplainer(model[\"classifier\"].predict, shap.sample(data_transformed,20) )\n",
    "#data_transformation=model[\"preprocessor\"].transform(Xtest[:4]).to_dense()\n",
    "#print(data_transformation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line takes almost two hours to run\n",
    "\n",
    "shap_values = explainer(data_transformed)\n",
    "\n",
    "#shap.plots.waterfall(shap_values[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"shap_values.npy\",shap_values)\n",
    "shap_values2 = np.load(\"shap_values.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:, \"num__Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.save(\"shap_values.npy\",shap_values)\n",
    "shap_values = np.load(\"shap_values.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0], data_transformed.iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(float(explainer.expected_value), shap_values[0, :], data_transformed.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
